---
title: "Group Project--Slack & Google Survey Data"
author: "Jiaqi, Joanna and Inga"
output: html_notebook
---
## 1. Installing and Loading Data Manipulation Packages

```{r}
#Install packages
install.packages("rjson")
install.packages("plyr")
install.packages("dplyr")
install.packages("tidyr")
install.packages("scales")
install.packages("ggplot2")

#Load packages
library(rjson)
library(plyr)
library(dplyr)
library(tidyr)
library(scales)
library(ggplot2)
```

## 2. Importing the Data & Data Cleaning

##WEEK5 WEEK5 WEEK5 WEEK5 WEEK5 WEEK5 WEEK5 WEEK5 WEEK5 WEEK5 WEEK5 5 WEEK5 WEEK5 WEEK5 WEEK5

```{r}
#Load json file into R 
W5D1<-fromJSON(file="wk5discuss2018/2018-01-23.json")
W5D2<-fromJSON(file="wk5discuss2018/2018-01-25.json")
W5D3<-fromJSON(file="wk5discuss2018/2018-01-26.json")
W5D4<-fromJSON(file="wk5discuss2018/2018-01-27.json")
W5D5<-fromJSON(file="wk5discuss2018/2018-01-30.json")
W5D6<-fromJSON(file="wk5discuss2018/2018-02-01.json")
W5D7<-fromJSON(file="wk5discuss2018/2018-02-07.json")
W5D8<-fromJSON(file="wk5discuss2018/2018-02-18.json")
W5D9<-fromJSON(file="wk5discuss2018/2018-02-19.json")
W5D10<-fromJSON(file="wk5discuss2018/2018-02-20.json")
W5D11<-fromJSON(file="wk5discuss2018/2018-02-21.json")
W5D12<-fromJSON(file="wk5discuss2018/2018-02-22.json")
W5D13<-fromJSON(file="wk5discuss2018/2018-02-25.json")
W5D14<-fromJSON(file="wk5discuss2018/2018-02-26.json")
W5D15<-fromJSON(file="wk5discuss2018/2018-03-01.json")


# Tranform list into data frame
W5D1DF<-do.call("rbind.fill", lapply(W5D1, as.data.frame))
W5D2DF<-do.call("rbind.fill", lapply(W5D2, as.data.frame))
W5D3DF<-do.call("rbind.fill", lapply(W5D3, as.data.frame))
W5D4DF<-do.call("rbind.fill", lapply(W5D4, as.data.frame))
W5D5DF<-do.call("rbind.fill", lapply(W5D5, as.data.frame))
W5D6DF<-do.call("rbind.fill", lapply(W5D6, as.data.frame))
W5D7DF<-do.call("rbind.fill", lapply(W5D7, as.data.frame))
W5D8DF<-do.call("rbind.fill", lapply(W5D8, as.data.frame))
W5D9DF<-do.call("rbind.fill", lapply(W5D9, as.data.frame))
W5D10DF<-do.call("rbind.fill", lapply(W5D10, as.data.frame))
W5D11DF<-do.call("rbind.fill", lapply(W5D11, as.data.frame))
W5D12DF<-do.call("rbind.fill", lapply(W5D12, as.data.frame))
W5D13DF<-do.call("rbind.fill", lapply(W5D13, as.data.frame))
W5D14DF<-do.call("rbind.fill", lapply(W5D14, as.data.frame))
W5D15DF<-do.call("rbind.fill", lapply(W5D15, as.data.frame))

```

## Combining the Data Source
```{r}
#Combine the data frames into one
Week5<-rbind.fill(W5D1DF,W5D2DF,W5D3DF,W5D4DF,W5D5DF,W5D6DF,W5D7DF,W5D8DF,W5D9DF,W5D10DF,W5D11DF,W5D12DF,W5D13DF,W5D14DF,W5D15DF)

Week5Clean<-select(Week5, -(attachments.title:attachments.id),-unread_count, -(reactions.count:root.ts))
                   
#Converts the timestamp ts "factor" into numeric data
Week5Clean$ts<-as.numeric(levels(Week5Clean$ts))[Week5Clean$ts]
Week5Clean$edited.ts<-as.numeric(levels(Week5Clean$edited.ts))[Week5Clean$edited.ts]
Week5Clean$thread_ts<-as.numeric(levels(Week5Clean$thread_ts))[Week5Clean$thread_ts]

#Creates a new column timedate and add it to the dataframe
Week5Clean<-mutate(Week5Clean, timedate=as.POSIXct(ts, origin="1970-01-01"))
Week5Clean<-mutate(Week5Clean, edited.timedate=as.POSIXct(edited.ts, origin="1970-01-01"))
Week5Clean<-mutate(Week5Clean, thread.timedate=as.POSIXct(thread_ts, origin="1970-01-01"))

#Filters the data frame and only keeps observations (rows) that have "N/A" in the subtype column.
Week5Clean<-filter(Week5Clean, is.na(subtype))

#Sorts messages by the time they were posted
Week5Clean <- Week5Clean[order(Week5Clean$ts),] 

#Add a unique key to each message
Week5Clean$message <- 1:nrow(Week5Clean) 

#Creates a new data frame just for messages 

Week5Messages<-select(Week5Clean, message, timedate, user, text)

# Recognize the post text as character data
Week5Messages$text<-as.character(Week5Messages$text)

#Check for duplicate data rows
duplicated(Week5Clean)

#Removes duplicate messages 
Week5Clean<-Week5Clean[!duplicated(Week5Clean[,c(1,2,5)]),]


```

##WEEK6 WEEK6 WEEK6 WEEK6 WEEK6 WEEK6 WEEK6 WEEK6 WEEK6 WEEK6 WEEK6 WEEK6 WEEK6 WEEK6 WEEK6

```{r}
#Load json file into R 
W6D1<-fromJSON(file="wk6discuss2018/2018-02-22.json")
W6D2<-fromJSON(file="wk6discuss2018/2018-02-27.json")
W6D3<-fromJSON(file="wk6discuss2018/2018-02-28.json")
W6D4<-fromJSON(file="wk6discuss2018/2018-03-01.json")
W6D5<-fromJSON(file="wk6discuss2018/2018-03-03.json")


# Tranform list into data frame
W6D1DF<-do.call("rbind.fill", lapply(W6D1, as.data.frame))
W6D2DF<-do.call("rbind.fill", lapply(W6D2, as.data.frame))

W6D3DF <- ldply(W6D3, function(x) {
   x[sapply(x, is.null)] <- NA
   unlisted_x <- unlist(x)
  d <- as.data.frame(unlisted_x)
  d <- as.data.frame(t(d), check.names=F)
  colnames(d) <- names(unlisted_x)
  return(d)
})

W6D4DF<-do.call("rbind.fill", lapply(W6D4, as.data.frame))
W6D5DF<-do.call("rbind.fill", lapply(W6D5, as.data.frame))

```
## Combining the Data Sources
```{r}

Week6<-rbind.fill(W6D1DF,W6D2DF, W6D3DF, W6D4DF,W6D5DF)

Week6Clean<-select(Week6,-inviter)
                   

#Converts the timestamp ts "factor" into numeric data
Week6Clean$ts<-as.numeric(levels(Week6Clean$ts))[Week6Clean$ts]
Week6Clean$edited.ts<-as.numeric(levels(Week6Clean$edited.ts))[Week6Clean$edited.ts]
Week6Clean$thread_ts<-as.numeric(levels(Week6Clean$thread_ts))[Week6Clean$thread_ts]

#Creates a new column timedate and adds it to the dataframe
Week6Clean<-mutate(Week6Clean, timedate=as.POSIXct(ts, origin="1970-01-01"))
Week6Clean<-mutate(Week6Clean, edited.timedate=as.POSIXct(edited.ts, origin="1970-01-01"))
Week6Clean<-mutate(Week6Clean, thread.timedate=as.POSIXct(thread_ts, origin="1970-01-01"))

#Filters the data frame and only keeps observations (rows) that have "N/A" in the subtype column.
Week6Clean<-filter(Week6Clean, is.na(subtype))

#Check for duplicate data rows
duplicated(Week6Clean)

#Removes duplicate messages 
Week6Clean<-Week6Clean[!duplicated(Week6Clean[,c(1,2)]),]

#Removes who reacted 
Week6Clean<-select(Week6Clean, -(reactions.name:reactions.users))
```

##Tidying the Data

```{r}

#Sorts messages by the time they were posted
Week6Clean <- Week6Clean[order(Week6Clean$ts),] 

#Add a unique key to each message
Week6Clean$message <- 1:nrow(Week6Clean) 

#Creates a new data frame just for messages 
Week6Messages<-select(Week6Clean, type, timedate, user, text, reactions.count)

# Recognize the post text as character data
Week6Messages$text<-as.character(Week6Messages$text)

# Count the number of characters in the text of each message and add a new column with this info
Week6Messages<-mutate(Week6Messages, CharLength=nchar(text))
```


## WEEK9 WEEK9 WEEK9 WEEK9 WEEK9 WEEK9 WEEK9 WEEK9 WEEK9 WEEK9 WEEK9 WEEK9 WEEK9 WEEK9 WEEK9 

```{r}
#Load json file into R 
W9D1<-fromJSON(file="wk9discuss2018/2018-01-25.json")
W9D2<-fromJSON(file="wk9discuss2018/2018-02-01.json")
W9D3<-fromJSON(file="wk9discuss2018/2018-03-07.json")
W9D4<-fromJSON(file="wk9discuss2018/2018-03-20.json")
W9D5<-fromJSON(file="wk9discuss2018/2018-03-21.json")
W9D6<-fromJSON(file="wk9discuss2018/2018-03-22.json")

# Tranform list into data frame and display it
W9D1DF<-do.call("rbind.fill", lapply(W9D1, as.data.frame))
W9D2DF<-do.call("rbind.fill", lapply(W9D2, as.data.frame))
W9D3DF<-do.call("rbind.fill", lapply(W9D3, as.data.frame))
W9D4DF<-do.call("rbind.fill", lapply(W9D4, as.data.frame))
W9D5DF<-do.call("rbind.fill", lapply(W9D5, as.data.frame))
W9D6DF<-do.call("rbind.fill", lapply(W9D6, as.data.frame))

#Combine the data frames into one
Week9<-rbind.fill(W9D1DF,W9D2DF,W9D3DF,W9D4DF,W9D5DF,W9D6DF)

Week9Clean<-select(Week9, -unread_count)
Week9Clean<-Week9Clean[-c(1:23),]
                   
#Converts the timestamp ts "factor" into numeric data
Week9Clean$ts<-as.numeric(levels(Week9Clean$ts))[Week9Clean$ts]
Week9Clean$edited.ts<-as.numeric(levels(Week9Clean$edited.ts))[Week9Clean$edited.ts]
Week9Clean$thread_ts<-as.numeric(levels(Week9Clean$thread_ts))[Week9Clean$thread_ts]

#Creates a new column timedate (based on the converted Unix timestamp) and adds it to the dataframe
Week9Clean<-mutate(Week9Clean, timedate=as.POSIXct(ts, origin="1970-01-01"))
Week9Clean<-mutate(Week9Clean, edited.timedate=as.POSIXct(edited.ts, origin="1970-01-01"))
Week9Clean<-mutate(Week9Clean, thread.timedate=as.POSIXct(thread_ts, origin="1970-01-01"))

#Filters the data frame and only keeps observations (rows) that have "N/A" in the subtype column.
Week9Clean<-filter(Week9Clean, is.na(subtype))

#Check for duplicate data rows
duplicated(Week9Clean)

#Removes who reacted 
Week9Clean<-select(Week9Clean, -(reactions.name:reactions.users))

```

##Tidying the Data  

```{r}

#Sorts messages by the time they were posted
Week9Clean <- Week9Clean[order(Week9Clean$ts),] 

#Add a unique key to each message
Week9Clean$message <- 1:nrow(Week9Clean) 

#Creates a new data frame just for messages 
Week9Messages<-select(Week9Clean, message, timedate, user, text, reactions.count, reply_count)

#Creates a new data frame just for edits
Week9Edits<-filter(select(Week9Clean, edited.timedate, edited.user, message.edited=message), !is.na(edited.timedate))

# Count the number of posts made grouped by user
summarise(group_by(Week9Messages, user), NumberOfPosts = n ())

# Tell R to recognize the post text as character data
Week9Messages$text<-as.character(Week9Messages$text)

# Count the number of characters in the text of each message and add a new column with this info
Week9Messages<-mutate(Week9Messages, CharLength=nchar(text))

```

##Survey Data Cleaning 

BELOW:
convert CSV to readable file

```{r}
ReadingData1<-read.csv("LADS-EDU Weekly Survey 2018 Responses Coded.csv")
```

BELOW:
remove unwanted variables
```{r}
ReadingData_edit<-(select(ReadingData1, -How.would.you.describe..Reading.1...R1..this.week...Interesting.:-What.sources.of.information.about.analytics.did.you.interact.with.this.week..other.than.class.readings...assignments....if.applicable.))

```
BELOW:
rename columns

```{r}
colnames(ReadingData_edit)[colnames(ReadingData_edit)=="What.week.are.you.entering.data.for."] <- "Week"

colnames(ReadingData_edit)[colnames(ReadingData_edit)=="When.did.you.get.started.on.your.work.for.class.this.week."] <- "Start Time"

colnames(ReadingData_edit)[colnames(ReadingData_edit)=="How.did.you.distribute.your.work.for.this.week."] <- "Work Distribution"

colnames(ReadingData_edit)[colnames(ReadingData_edit)=="How.did.you.organize.your.work.for.class.this.week."] <- "Work Organization"

colnames(ReadingData_edit)[colnames(ReadingData_edit)=="What.did.you.find.most.challenging.about.the.work.you.did.for.class.this.week."] <- "Work Challenge"

colnames(ReadingData_edit)[colnames(ReadingData_edit)=="Stu.ID"] <- "user"
```
BELOW:
change "Timestamp" format to match format from JSON files

```{r}

ReadingData_edit$Timestamp<- as.POSIXct(ReadingData_edit$Timestamp,format="%m/%d/%Y%H:%M:%S")
```
BELOW:
Subset data from survey

```{r}
ReadingData_Week5 <- ReadingData_edit[ which(ReadingData_edit$Week=="Wk 5 - Predictive Modelling 1"),] 

ReadingData_Week6 <- ReadingData_edit[ which(ReadingData_edit$Week=="Wk 6 - Predictive Modelling 2"),] 

ReadingData_Week9 <- ReadingData_edit[ which(ReadingData_edit$Week=="Wk 9 - Social Network Analysis 1"),]

```


## 3. Analysis

BELOW: plot use over time 

```{r}

ggplot(data=Week5Clean, aes(Week5Clean$timedate)) + geom_histogram(bins="10", col="black", aes(fill=..count..)) +labs(title="Histogram of Message Count") +labs (x="Time", y="Count")
```

```{r}
ggplot(data=Week9Clean, aes(Week9Clean$timedate)) + geom_histogram(bins="10", col="black", aes(fill=..count..)) +labs(title="Histogram of Message Count") +labs (x="Time", y="Count")

```

```{r}
ggplot(data=Week6Clean, aes(Week6Clean$timedate)) + geom_histogram(bins="10", col="black", aes(fill=..count..)) +labs(title="Histogram of Message Count") +labs (x="Time", y="Count")

```


```{r}

Weeksall<-rbind.fill(Week5Clean,Week6Clean,Week9Clean)
```
Below: visualize message count to time posted (visualize when students complete survey)
```{r}

ggplot(data=Weeksall, aes(Weeksall$timedate)) + geom_histogram(bins="20", col="black", aes(fill=..count..)) +labs(title="Histogram of Message Count") +labs (x="Time", y="Count") 
    
```

```{r}

ggplot(data=ReadingData_Week9, aes(ReadingData_Week9$Timestamp)) + geom_histogram(bins="20", col="green", aes(fill=..count..)) +labs(title="Histogram") +labs (x="Time", y="Count")

```

Below: discover patterns of student answers in survey 

```{r}

ggplot(ReadingData_Week9, aes(ReadingData_Week9$`Start Time`, ReadingData_Week9$`Work Distribution`))+ geom_point() + stat_sum(aes(group = 1))+ theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

```

```{r}

ggplot(ReadingData_Week9, aes(ReadingData_Week9$`Work Distribution`, ReadingData_Week9$`Work Organization`))+ geom_point() + stat_sum(aes(group = 1))+ theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

```

```{r}

ggplot(ReadingData_Week9, aes(ReadingData_Week9$`Start Time`, ReadingData_Week9$`Work Organization`))+ geom_point() + stat_sum(aes(group = 1))+ theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

```
Below: combine all 3 survey weeks 

```{r}

ReadingData_3weeks <- rbind.fill(ReadingData_Week5, ReadingData_Week6, ReadingData_Week9)

ggplot(ReadingData_3weeks, aes(ReadingData_3weeks$`Work Distribution`,ReadingData_3weeks$`Work Challenge`))+ geom_point() + stat_sum(aes(group = 1))

```
Below: compare what students found challenging and when they start their work

```{r}

ggplot(ReadingData_3weeks, aes(ReadingData_3weeks$`Start Time`,ReadingData_3weeks$`Work Challenge`))+ geom_point() + stat_sum(aes(group = 1))

```
Below: combine timestamp in slack data to survey data

```{r}


merge(ReadingData_Week9, Week9Clean[, c("user", "timedate")], by="user", all = TRUE)

ReadingData_Week9$slacktimedate <- Week9Clean$timedate[match(ReadingData_Week9$user, Week9Clean$user)]

```



BELOW: compare when students posted in slack and what they found challenging 

```{r}

g= ggplot(ReadingData_3weeks, aes(ReadingData_3weeks$slacktimedate,ReadingData_3weeks$`Work Challenge`))+ geom_point() 
g = g + scale_x_datetime(name = "Date", 
                         breaks = date_breaks("2 days"),
                         labels = date_format(format = "%b %d"),
                         limits = c(as.POSIXct("2018-02-18 00:00:00"), as.POSIXct("2018-03-25                         00:00:00")),
                         expand = c(0,0))
g = g + theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
plot(g)

```


```
```

BELOW: compare when students started to when they posted on slack 

```{r}

g= ggplot(ReadingData_3weeks, aes(ReadingData_3weeks$slacktimedate,ReadingData_3weeks$`Start Time`))+ geom_point() 
g = g + scale_x_datetime(name = "Date", 
                         breaks = date_breaks("2 days"),
                         labels = date_format(format = "%b %d"),
                         limits = c(as.POSIXct("2018-02-18 00:00:00"), as.POSIXct("2018-03-25                         00:00:00")),
                         expand = c(0,0))
g = g + theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
plot(g)



```


## The End